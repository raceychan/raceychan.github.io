"use strict";(self.webpackChunkblogs=self.webpackChunkblogs||[]).push([[9081],{7677:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"encapsulation-beyond-syntax-do-access-modifiers-still-matter","metadata":{"permalink":"/ja/blog/encapsulation-beyond-syntax-do-access-modifiers-still-matter","source":"@site/blog/2025-08-03T14_29-encapsulation-beyond-syntax-do-access-modifiers-still-matter/content.md","title":"Encapsulation Beyond Syntax: Do Access Modifiers Still Matter?","description":"gears","date":"2025-08-03T00:00:00.000Z","tags":[{"inline":false,"label":"python","permalink":"/ja/blog/tags/python","description":"general dicussion about programming in python"},{"inline":false,"label":"OOP","permalink":"/ja/blog/tags/oop","description":"Object-oriented programming principles and practices"}],"readingTime":11.065,"hasTruncateMarker":true,"authors":[{"name":"raceychan","title":"author of lihil, a developer.","url":"https://github.com/raceychan","page":{"permalink":"/ja/blog/authors/raceychan"},"imageURL":"https://github.com/raceychan.png","key":"raceychan"}],"frontMatter":{"slug":"encapsulation-beyond-syntax-do-access-modifiers-still-matter","title":"Encapsulation Beyond Syntax: Do Access Modifiers Still Matter?","authors":["raceychan"],"tags":["python","oop"]},"unlisted":false,"nextItem":{"title":"Design Patterns You Should Unlearn in Python-Part2","permalink":"/ja/blog/design-patterns-you-should-unlearn-in-python-part2"}},"content":"![gears](https://unsplash.com/photos/JBZvYieOmCQ/download?ixid=M3wxMjA3fDB8MXxzZWFyY2h8N3x8bWVjaGFuaWNzfGVufDB8fHx8MTc1NDI0NjQ1OXww&force=true&w=1920)\\n\\nEncapsulation in Python is one of those topics that often gets brushed off,  either as unnecessary boilerplate or as baggage from statically typed languages like Java and C++. In many Python teams, it\u2019s treated as optional, or worse, irrelevant.\\n\\nBut this casual attitude has a cost.\\n\\nAs Python takes on a bigger role in enterprise software, especially with the rise of AI, more teams are building larger, more complex systems together. Without proper encapsulation, internal changes in one part of the codebase can leak out and break things for everyone else. It becomes harder to reason about code boundaries, harder to collaborate, and harder to move fast without stepping on each other\u2019s toes.\\n\\nIn this post, we\u2019ll talk about **why encapsulation still matters in Python**, why it\u2019s becoming increasingly important, and how to approach it in a way that actually fits the language and its philosophy.\\n\\nAnd just in case you\u2019re wondering: **no, this won\u2019t be one of those \\"here\u2019s how to mimic Java\u2019s access modifiers in Python\\" posts.** We\'re going deeper than that.\\n\\n\x3c!--truncate--\x3e\\n\\n## **Access Modifiers: What They Are, and What They Look Like**\\n\\nWhen people think of encapsulation, they often jump straight to **access modifiers**, and it\u2019s easy to see why. In many languages, access modifiers are the main way to draw boundaries between internal and external code.\\n\\nIn Java, for example, you have explicit keywords:\\n```java\\n\\npublic class UserService {\\n    protected UserRepository repository;\\n\\n    public void register(User user) {\\n        // ...\\n    }\\n}\\n```\\n\\nHere, `protected` means no one outside the class(and its subclasses) can touch `repository`, and `public` means anyone can call `register`.\\n\\n> `protected` is less strict in java, other classes **in the same package** can access protected member as well.\\n\\nPython, on the other hand, doesn\u2019t have strict access modifiers. Instead, it relies on naming conventions:\\n\\n```python\\nclass UserService:\\n    def __init__(self, repo: UserRepository):\\n        self._repository = repo\\n\\n    def register(self, user: UserInfo):\\n        ...\\n```\\n\\nIn this example, the leading underscore in `_repository` is Python\u2019s way of saying \u201chey, this is internal,  don\u2019t mess with it.\u201d But it\u2019s just a convention. You _can_ still access it from the outside. If your type checker is configured correctly, it might warn you, but nothing at the interpreter level will stop you. No exceptions will be raised.\\n\\n\\n### **Why Do We Need Encapsulation?**\\n\\nThe primary reason is simple: **to draw a line between what\'s internal and what\'s public**. That line lets other developers,  or even future-you,  know what\u2019s safe to rely on and what isn\u2019t. When a method or attribute is marked internal (e.g. with a leading underscore), you\'re saying: _this is part of the implementation, not the interface._\\n\\nWhy does that matter? Because once other parts of the codebase,  or worse, external systems,  start depending on your internal details, **you lose the freedom to change them**. If you need to refactor, simplify, or remove something, you risk breaking unknown callers.\\n\\nThis is not a new problem. Software engineering has wrestled with this for decades, and the solution has been expressed through principles like the **Open/Closed Principle (OCP)**:\\n\\n> _Software entities should be open for extension but closed for modification._\\n\\nEncapsulation supports this by letting you change how things work internally, **without changing the parts others depend on**. When we design a class with a clear public interface and hidden internals, we make it easier to evolve the code over time without introducing regressions.\\n\\nWhen we _do_ need to expose something, we can still preserve encapsulation using tools like `@property`. This lets us provide a stable public interface, while keeping the flexibility to change how things work behind the scenes,  coercing types, adding guards, lazy-loading data, etc.\\n\\nIn general, when a class represents business logic, it\u2019s often a good idea to **default to making members protected** and **only expose public methods that represent meaningful, validated operations**.\\n\\nTake this example:\\n\\n```python\\n@dataclass\\nclass UserInfo:\\n    email: str\\n    name: str\\n    role: str = \\"user\\"\\n\\nclass UserService:\\n    def __init__(self, user_repo: UserRepository):\\n        self._repo = user_repo\\n\\n    def register(self, user: UserInfo):\\n        self._validate_email(user.email)\\n        self._validate_role(user.role)\\n        self._repo.add_user(user)\\n\\n    def _validate_email(self, email: str): ...\\n    def _validate_role(self, role: str): ...\\n```\\n\\nHere, we don\'t want other services to call `_validate_email` or `_repo.add_user()` directly. Those are internal details that can change. What we _do_ want them to use is the stable `register()` interface.\\n\\n### **What Happens Without It?**\\n\\nNow let\u2019s imagine we didn\u2019t bother with any of this,  we just exposed everything.\\n\\n```python\\n# Somewhere else in the codebase\\nservice = UserService()\\nuser = UserProfile(email=\\"a@example.com\\", name=\\"Alice\\")\\nservice.repository.add_user(user)  # Uh-oh\\n```\\n\\nOther parts of the system might start calling `user_repo.add_user()` directly, bypassing all the validation logic in `UserService.register()`. That could lead to subtle, inconsistent behavior, or worse,  bad data getting into your system.\\n\\nOr maybe someone starts reusing `_validate_email()` from somewhere else. But since it was never meant to be used externally, one day we remove it during a refactor,  and now their code breaks. Whose fault is it? Technically not yours, but it sure won\'t feel that way when you\u2019re on the hook for fixing it.\\n\\nWhen everything is public, **every change becomes dangerous**. Before touching anything, you have to check who\u2019s using it. Modify a method? Now you\u2019re spelunking through half the codebase, updating every dependent. It\u2019s a maintenance nightmare.\\n\\nEncapsulation reduces that cognitive load. It tells you what you can change freely and what you need to be careful with. It gives your code **safe zones**.\\n\\n### **Why We Didn\u2019t Need It as Much Before**\\n\\nSo why hasn\u2019t this been a bigger issue in Python until now?\\n\\nBecause for a long time, Python wasn\u2019t used to build large systems with lots of contributors. It was a scripting language,  great for small utilities, automation, scientific experiments, or one-off data analyses. In those cases, it didn\u2019t matter if you exposed your internals. You were often the only one touching the code anyway.\\n\\nBut that\u2019s changed. Python is now powering **production-grade systems**, especially in AI, web services, and data infrastructure. With more teams, more contributors, and more complexity, the lack of boundaries starts to hurt.\\n\\nAlso, before Python 3.6, we simply didn\u2019t have the tools to enforce encapsulation effectively. Without type hints and the ecosystem around them, it was hard to even notice violations of protected members, let alone prevent them. Now, with tools like pyright, mypy, and IDEs like VSCode, we can catch those violations early.\\n\\n![procted_attr](./protected_attr.png)\\n\\n- Example vscode config from lihil\\n\\n    ```toml\\n    [tool.pyright]\\n    exclude = [\\"tests\\"]\\n    include = [\\"lihil/*.py\\"]\\n    python_version = \\"3.10\\"\\n    typeCheckingMode = \\"strict\\"\\n    ```\\n\\n## when to use access modifier and when not to\\n\\nNot all classes are created equal. Their purpose affects how much encapsulation you really need,  and what kind.\\n\\nLet\u2019s take two common categories: **data classes** and **service classes**.\\n\\nData classes are meant to carry state. But sometimes we start stuffing behavior and dependencies into them,  and that\u2019s when things get messy. Consider this example:\\n\\n```python\\n@dataclass\\nclass UserManager:\\n    users: list[UserInfo]\\n    engine: AsyncEngine  # external dependency\\n\\n    def add_user(self, user_info: UserInfo):\\n        ...\\n```\\n\\nAt first glance, this looks fine. But `engine` is not really just data,  it\u2019s a dependency. It probably shouldn\'t be public, but because this is a dataclass, _everything is public by default_. You don\u2019t get any real control over what\u2019s exposed, which can lead to tight coupling and leaky abstractions.\\n\\nNow let\u2019s flip the problem: a service class with too many internal configuration values.\\n\\n```python\\nclass FileDownloader:\\n    def __init__(self, session: ClientSession):\\n        self._session = session\\n        self._max_concurrent = 3\\n        self._max_file_size = 100 * 1024 * 1024\\n        self._timeout = 10\\n        self._retries = 2\\n        self._allow_redirect = True\\n        # and the list goes on...\\n\\n    def download(self, url: str):\\n        ...\\n```\\n\\nEach of these config values might need to be accessed from outside the class, but none of them are really _business logic_. So now you\'re stuck adding five `@property` methods just to make them selectively public. That\'s tedious and clutters the class with boilerplate.\\n\\nA better approach? Extract the config into a separate dataclass:\\n\\n```python\\n@dataclass\\nclass DownloadConfig:\\n    max_concurrent: int = 3\\n    max_file_size: int = 100 * 1024 * 1024\\n    timeout: int = 10\\n    retries: int = 2\\n    allow_redirect: bool = True\\n\\nclass FileDownloader:\\n    def __init__(self, session: ClientSession, config: DownloadConfig):\\n        self._session = session\\n        self._config = config\\n\\n    @property\\n    def config(self) -> DownloadConfig:\\n        return self._config\\n```\\n\\nNow the `FileDownloader` focuses on behavior, and the data lives in a plain, easy-to-inspect structure. No clutter. No second-guessing access modifiers.\\n\\nIf you mix state and behavior carelessly, encapsulation decisions get exhausting,  you\u2019ll find yourself manually evaluating every attribute and method. But when the design is clear, the modifiers fall into place naturally.\\n\\n### Anti-patterns\\n\\n\\nThe worst-case scenario is blindly adding getters and setters for everything,  especially when they don\u2019t do anything useful. If you\u2019re not doing validation, type coercion, or state transformation, a setter is just noise.\\n\\nLet\u2019s look at an example:\\n\\n```python\\nclass Project:\\n    def __init__(self, status: str):\\n        self._status = status\\n\\n\\t@property\\n    def status(self) -> str: return self._status\\n\\n\\t@status.setter\\n    def status(self, status: str): self._status = status\\n```\\n\\nWhat value does this add? The methods don\u2019t protect anything. They don\u2019t clarify intent. They just waste space and give a false sense of encapsulation.\\n\\nNow compare that to this alternative:\\n\\n```python\\nclass Project:\\n    def __init__(self, status: str):\\n        self._status = status\\n\\n    def mark_as_completed(self, reason: str | None = None):\\n        \\"\\"\\"Mark the project as completed, with an optional reason for tracking.\\"\\"\\"\\n        if self._status == \\"comleted\\":\\n\\t        return\\n\\t\\tif self._status not in (\\"started\\", \\"running\\"):\\n\\t\\t    raise InvalidStatusError(self._status)\\n\\n        self._status = \\"completed\\"\\n        if reason:\\n            self._log_reason(reason)\\n```\\n\\nThis version is doing real work. You can pass multiple arguments. The method names express intent. The docstrings help the reader understand context. It\u2019s much more maintainable and far less dogmatic.\\n\\nAnd while we\u2019re at it: don\u2019t abuse **inheritance** either. You can spend all day trying to protect internals from subclasses,  or you can just stop subclassing altogether.\\n\\nSometimes the simpler answer is to design your class as effectively **final**, and let other classes **depend on it via composition**. You avoid the pitfalls of fragile base classes, and you make encapsulation easier to reason about.\\n\\nYes, _composition over inheritance_. Not always. But definitely more often than some legacy tutorials would have you believe.\\n\\n\\n### **Encapsulation Beyond Classes**\\n\\nEncapsulation isn\u2019t just about hiding attributes inside a class. The same principle applies at higher levels,  **modules**, **packages**, and even **entire applications**. It\'s all about controlling what gets exposed and what stays internal.\\n\\nLet\u2019s look at a few examples.\\n\\n### Python (Module-Level)\\n\\n```python\\n# token_service/__init__.py \\n\\nfrom .service import TokenService  \\n__all__ = [\\"TokenService\\"]  # Everything else stays internal\\n```\\n\\nYou can also use leading underscores for private helpers:\\n\\n```python\\n# token_service/utils.py \\ndef _sign_payload(...): ...\\n```\\n\\n\\nThis tells both humans and tools: \\"this isn\u2019t part of the public interface.\\"\\n\\n### TypeScript (File/Module-Level)\\n\\n```ts\\n// token_service.ts\\n\\nexport class TokenService {}       // public\\nclass InternalCache {}             // not exported = internal to the module\\n```\\nIf it\u2019s not exported, it\u2019s not part of the API. That\u2019s module-level encapsulation.\\n\\n---\\n\\nAnd you can scale this even further.\\n\\n- At the **package level**, you decide which modules to expose in `__init__.py` or in your `pyproject.toml`.\\n- At the **application level**, you expose only selected routes in your web API or specific commands in your CLI. Everything else stays behind the scenes.\\n\\n\\n## Encapsulation beyond code\\n\\nEncapsulation doesn\u2019t stop at classes, functions, or modules, it applies at the **architectural level**, too.\\n\\nIn a microservice-based system, each service is an isolated unit with its own data, logic, and internal state. You don\u2019t (and shouldn\u2019t) reach across service boundaries to query another service\u2019s database or call its internal methods. Instead, communication happens through **well-defined interfaces**, usually REST, gRPC, or message queues.\\n\\nThis is encapsulation at the system level:\\n\\n- A service only exposes the API endpoints it wants others to use.\\n- Internal components like DAOs, caches, feature flags, or job queues are entirely hidden.\\n- Breaking changes can be avoided because external consumers never depend on internal details.\\n\\nA good example would be an **API Gateway**. To the caller, it stays transparent. But behind the scenes, the gateway might route the request to multiple services, apply authentication, logging, retries, or circuit-breaking logic. None of that is exposed. The caller doesn\'t know, and doesn\'t need to.\\n\\nIt\u2019s the same idea as `private` or `protected`, just scaled out over a network.\\n\\nWhether you\u2019re defining a Python method, a Go module, or a service boundary in your infrastructure, the principle is the same:\\n\\n> **Hide internal details. Expose a clean, intentional interface. Decouple everything else.**\\n\\n\\n\\n### **Wrapping Up**\\n\\nEncapsulation isn\u2019t about following rules,  it\u2019s about creating **boundaries that protect your code**. Whether you\u2019re building a Python library, designing a class, organizing a module, or architecting an entire system, the goal is the same: **make the interface clear, keep the internals private, and give yourself room to evolve**.\\n\\nIn Python, we don\u2019t have enforced access modifiers,  and that\u2019s fine. We have conventions, type checkers, and design discipline. What matters is that you _use them deliberately_.\\n\\nDon\u2019t add encapsulation for its own sake. But don\u2019t dismiss it just because you\u2019re writing Python. If anything, Python\u2019s flexibility makes it _more_ important to clearly mark your boundaries.\\n\\nStart by separating your data classes from your service classes. Use underscores to guide intention. Avoid meaningless setters. Prefer real methods with real names. And think in terms of public interfaces,  whether you\'re building a class or an entire API."},{"id":"design-patterns-you-should-unlearn-in-python-part2","metadata":{"permalink":"/ja/blog/design-patterns-you-should-unlearn-in-python-part2","source":"@site/blog/2025-06-20T17_34-design-patterns-you-should-unlearn-in-python-part2/content.md","title":"Design Patterns You Should Unlearn in Python-Part2","description":"image-1.jpg","date":"2025-06-20T00:00:00.000Z","tags":[{"inline":false,"label":"python","permalink":"/ja/blog/tags/python","description":"general dicussion about programming in python"},{"inline":true,"label":"design patterns","permalink":"/ja/blog/tags/design-patterns"},{"inline":false,"label":"OOP","permalink":"/ja/blog/tags/oop","description":"Object-oriented programming principles and practices"}],"readingTime":10.225,"hasTruncateMarker":true,"authors":[{"name":"raceychan","title":"author of lihil, a developer.","url":"https://github.com/raceychan","page":{"permalink":"/ja/blog/authors/raceychan"},"imageURL":"https://github.com/raceychan.png","key":"raceychan"}],"frontMatter":{"slug":"design-patterns-you-should-unlearn-in-python-part2","title":"Design Patterns You Should Unlearn in Python-Part2","authors":["raceychan"],"tags":["python","design patterns","oop"],"toc_min_heading_level":2,"toc_max_heading_level":5},"unlisted":false,"prevItem":{"title":"Encapsulation Beyond Syntax: Do Access Modifiers Still Matter?","permalink":"/ja/blog/encapsulation-beyond-syntax-do-access-modifiers-still-matter"},"nextItem":{"title":"Design Patterns You Should Unlearn in Python-Part1","permalink":"/ja/blog/design-patterns-you-should-unlearn-in-python-part1"}},"content":"![image-1.jpg](https://unsplash.com/photos/so5nsYDOdxw/download?ixid=M3wxMjA3fDB8MXxhbGx8fHx8fHx8fHwxNzUwNDQyOTM2fA&force=true&w=1920)\\n\\nEver since the *Gang of Four* released their legendary *Design Patterns* book in the 90s, \\"design patterns\\" have been a cornerstone of how developers talk about software architecture. Over time, though, the term itself has grown fuzzier. When someone mentions a pattern today, they might be referring to:\\n\\n- The **intent** behind the pattern: the problem it\'s trying to solve.\\n- The **implementation**: the exact class structure or code to achieve it.\\n\\nWhen we talk about \u201cdesign patterns you should unlearn in Python,\u201d we\u2019re talking about the second kind: the implementation. These patterns still solve real problems. But in Python, the way you solve them often looks nothing like the solutions shown in C++ or Java.\\n\\nThat\u2019s the key idea behind this series. The moral is simple:\\n\\n> Bears learn to climb trees to reach food. But Eagles do not climb, they fly.\\n\\nIn Part 1, we took apart the Builder and Singleton patterns, showing how Python\u2019s features (like default arguments or modules) make many \u201cclassic\u201d implementations unnecessary or even counterproductive.\\n\\nNow, let\u2019s move on to two more patterns: **Flyweight** and **Prototype**. Both solve real problems. But as you\'ll see, Python gives us simpler, more natural ways to solve them.\\n\\n\x3c!-- truncate --\x3e\\n\\n---\\n\\n## Flyweight Pattern: Sharing to Save Memory\\n\\nIn Part 1, we looked at Singleton, a classic example of overengineering in Python, where a simple module or closure often does the job better.\\n\\nFlyweight is closely related. If Singleton is about having **only one instance per class**, Flyweight is about having **one instance per unique set of parameters**. Both patterns try to avoid excessive object creation, just in different ways.\\n\\nBut here\u2019s the problem: developers often reach for Singleton when they really need Flyweight. Or worse, they don\u2019t need either.\\n\\nHere\u2019s a quick litmus test:\\n\\n- **No constructor parameters** (or they\u2019re always the same)? You probably don\u2019t need a class. Just use a module-level object.\\n- **Constructor parameters matter**? Then Singleton is likely the wrong choice, a Flyweight-style pattern might be more appropriate.\\n\\n### Flyweight from the book\\n\\nThe Flyweight pattern was originally created to handle memory constraints in object-heavy applications. As the GoF book puts it:\\n\\t\\n> \\"Use sharing to support large numbers of fine-grained objects efficiently.\\"\\n\\t\\nThe classic example is a document editor that represents thousands of characters. Each character with its own font, size, and position is a tiny object, but when you have tens of thousands of them, the memory cost adds up fast. Creating one full object per character can easily exhaust memory, especially in older environments with tight constraints.\\n\\n> The book has detailed illustration on this, we will append links to this at the bottom of th article.\\n\\nFlyweight solves this by reusing shared parts of each character(like the glyph and font) and storing only the unique parts separately.\\n\\nIf you search online for how to implement the Flyweight pattern in Python, you\u2019ll often run into examples like this:\\n\\n```python\\nfrom typing import ClassVar\\nfrom dataclasses import dataclass\\n\\n\\nclass User:\\n    _users: ClassVar[dict[tuple[str, int], \\"User\\"]] = {}\\n\\n    def __new__(cls, name: str, age: int) -> \\"User\\":\\n        if not (u := cls._users.get((name, age))):\\n            cls._users[(name, age)] = u = super().__new__(cls)\\n        return u\\n\\n    def __init__(self, name: str, age: int):\\n       self.name = name\\n       self.age = age\\n```\\n\\n\\nThis approach that uses `__new__` in combination with a class variable to control the creation of instances, similar to what we had in the singleton pattern, is an example of over-engineering most of the time, and tends to open a rabbit hole of problems. \\n\\nThe core issue is that **mutable class variables are shared across all instances, and across subclasses too**. This makes them very easy to mutate accidentally from multiple places in your codebase. Because the cache lives at the class level, it becomes difficult to control, track, or test.\\n\\nThe use of the `__new__` magic method makes things even worse. It bypasses the usual object creation flow, and can easily create surprising behavior, especially when subclassing. For example, would you expect this code to raise an error?\\n\\n```python\\nu = User(\\"user\\", 20)\\nassert type(u) is User\\n```\\n\\nImaging someone inherit your class:\\n\\n```python\\nclass Admin(User):\\n    ...\\n\\n\\nIn [6]: Admin(\\"user\\",20)\\nOut[6]: <__main__.Admin at 0x7c123e18b650>\\n\\nIn [7]: User(\\"user\\",20)\\nOut[7]: <__main__.Admin at 0x7c123e18b650>\\n```\\n\\nIf you\'re working in a larger codebase or using third-party tools that instantiate a sbuclass of `User` without knowing about your custom `__new__`, these surprises turn into hard-to-debug runtime errors. Once you start rewriting object creation logic with __new__ and shared caches, you\'re on shaky ground. It\u2019s fragile, implicit, and rarely worth it in Python.\\n\\n### Better approach: A factory function with cache:\\n\\n```python\\nfrom functools import lru_cache\\n\\n@lru_cache\\ndef create_user(name: str, age: int) -> User:\\n    return User(name, age)\\n```\\n\\nThis avoids all the pitfalls of `__new__` and class-level state. It\u2019s simple, explicit, and safe.\\n\\nUnlike the previous implementation, `lru_cache` guarantees that `create_user(...)` always returns a real `User` and not its subclasses. And because the cache is tied to the function, not the class, instances can\'t accidentally mutate or replace shared state. You can reason about it just like any other function: same inputs, same output, always predictable.\\n\\none small caveat is to avoid using it like this where you put the `lru_cache` decorated function side a class as a method. \\n\\n```python\\nclass UserFactory:\\n    @lru_cache\\n    def create_user(self, name: str, age: int) -> User:\\n        return User(name, age)\\n```\\n\\nIn this case, every instance of `UserFactory` will have its own separate cache. That\u2019s because `self` is included in the arguments being hashed. So calling `factory1.create_user(\\"Alice\\", 30)` and `factory2.create_user(\\"Alice\\", 30)` won\u2019t hit the same cache, even if everything else is the same.\\n\\nAlso, when constructor params contain mutable objects, you might do a little DIY, just like what python `re.compile` did.\\n\\n```python title=\\"re.compile from python 3.11\\"\\n_cache = {}  # ordered!\\n\\n_MAXCACHE = 512\\ndef _compile(pattern, flags):\\n    # internal: compile pattern\\n    if isinstance(flags, RegexFlag):\\n        flags = flags.value\\n    try:\\n        return _cache[type(pattern), pattern, flags]\\n    except KeyError:\\n        pass\\n    if isinstance(pattern, Pattern):\\n        if flags:\\n            raise ValueError(...)\\n        return pattern\\n    if not _compiler.isstring(pattern):\\n        raise TypeError(...)\\n    if flags & T:\\n        import warnings\\n        warnings.warn(...)\\n    p = _compiler.compile(pattern, flags)\\n    if not (flags & DEBUG):\\n        if len(_cache) >= _MAXCACHE:\\n            # Drop the oldest item\\n            try:\\n                del _cache[next(iter(_cache))]\\n            except (StopIteration, RuntimeError, KeyError):\\n                pass\\n        _cache[type(pattern), pattern, flags] = p\\n    return p\\n```\\n\\n\\n### Prototype Pattern: What Problem Is It Solving?\\n\\nNow that we\u2019ve seen how the Flyweight pattern often collapses into a simple caching function in Python, let\u2019s look at another pattern that frequently gets reinterpreted (or misunderstood) in modern code: **Prototype**.\\n\\nPrototype is especially interesting because the way it\u2019s presented in many online tutorials today, \u201creuse object state to create new objects\u201d, is not actually its original focus. In the _Design Patterns_ book, the problem it solves is more architectural, and has to do with **decoupling object creation from a framework that doesn\u2019t know about your custom types**.\\n\\nImagine you\'re building a music editor using a GUI framework. There\'s a `GraphicTool` class provided by the framework that users interact with to create graphics.\\n\\n```python\\nclass GraphicTool:\\n    def click(self) -> Graphics: ... \\n    \\n# when users click the GraphicTool it would return a graph object that would be rendered on the screen.\\n```\\n\\nYou define your own classes like `MusicalNote`, which inherit from the base `Graphics` type:\\n\\n```python\\nfrom gui import Graphics\\n\\nclass MusicalNote(Graphics):\\n\\tdef __init__(self, note: str = \\"C4\\"):\\n\\t    self.note = note\\n```\\n\\nHere\u2019s the problem the GoF book describes:\\n\\n> \\"\xa0GraphicTool presents a problem to the framework designer. The classes for notes and staves are specific to our application, but the GraphicTool class belongs to the framework. GraphicTool doesn\'t know how to create instances of our music classes to add to the score.\\"\\n\\nAnd it continues:\\n\\n> \\"\xa0The question is, how can the framework use it to parameterize instances of GraphicTool by the\xa0_class_\xa0of Graphic they\'re supposed to create?\\"\\n\\nIn short, although `GraphicTool` knows how to work with the base `Graphics` type defined by the library, it has no knowledge of the concrete subclasses like `MusicalNote` that are defined in the client application. Yet it is the GUI library who must create and place these objects when users interact with the tool palette.\\n\\nThis creates a tension. The framework can\u2019t be expected to hardcode support for every user-defined subclass of `Graphics`. Nor is it practical to subclass `GraphicTool` for each new graphic type the client might introduce. To address this, the **Prototype** pattern offers a solution: rather than teaching the framework how to construct every possible object, the client supplies a preconfigured instance(a prototype) that the framework can clone whenever a new object is needed.\\n\\nUnder this pattern, you define a `clone()` method on your custom graphic class such as `MusicalNote`. This method returns a new copy of the object, allowing `GraphicTool` to remain completely unaware of the specific type it is cloning. It simply holds a reference to the prototype and invokes `proto.clone()` whenever it needs to create a new instance. In this way, the creation logic stays entirely in the hands of the client, while the framework remains flexible and extensible.\\n\\n```python\\nclass GraphicTool:\\n    def __init__(self, proto: Graphics):\\n        self.proto = proto\\n        \\n    def click(self) -> Graphic:\\n        return self.proto.clone()\\n```\\nFrom the client code, you might do:\\n```python\\ng = GraphicTool(proto=MusicalNote())\\n```\\nThis works because you implement a `clone()` method on your custom class, and the tool just calls that to get a new object.\\n\\nBut in Python, this approach feels a little... off. Wouldn\u2019t you just pass a **class** or **factory function** instead? That\u2019s how we handle this kind of situation all the time. It\u2019s cleaner, easier to read, and plays nicer with the rest of the language:\\n\\n\\n```python\\nclass GraphicTool:\\n    def __init__(self, graph_factory: Callable[..., Graphics]):\\n        self.graph_factory = graph_factory\\n        \\n    def click(self) -> Graphic:\\n        return self.graph_factory()\\n        \\n# from client code\\ng = GrpahicTool(graph_factory=MusicalNote)\\n\\n# To create with default values, pass factory, say lambda: MusicalNote(note=\\"C5\\")\\ng = GraphicTool(graph_factory=lambda: MusicalNote(note=\\"C5\\"))\\n```\\n\\nThis pattern of passing a callable is everywhere in Python. From `asyncio`\'s `set_task_factory()` to the `target` parameter in `threading.Thread`, Python developers lean on factories because they\u2019re straightforward and flexible.\\n\\n### why didn\u2019t the **Gang of Four** book recommend passing a factory instead? \\n\\nThe book itself provides the answer:\\n> \\" Prototype is particularly useful with static languages like C++, where classes are not objects, and little or no type information is available at run-time. It\'s less important in languages like Smalltalk or Objective C that provide what amounts to a prototype (i.e., a class object) for creating instances of each class.\\"\\n\\nIn other words, languages like C++ (especially pre-C++11) didn\'t support passing classes or lambdas as first-class objects. You couldn\u2019t treat types as values or pass around factory functions. That\u2019s why the Prototype pattern , cloning a sample object instead of constructing a new one, made sense in those contexts.\\n\\nBut in dynamic, reflective languages like Python, where classes and functions are first-class citizens, we have simpler, clearer alternatives. Instead of cloning objects with a `clone()` method, we just pass a **factory function or class constructor** ,  and we get more flexibility, better readability, and tighter integration with the language ecosystem.\\n\\nSo while the Prototype pattern remains a clever solution to a real problem in statically typed languages, in Python, it\u2019s often **an unnecessary workaround** for a problem we don\u2019t have.\\n\\n### Wrapping Up\\n\\nFlyweight and Prototype both solve real problems: minimizing object creation and decoupling object construction from frameworks. \\n\\nBut the way they were designed in the context of C++ and Java doesn\'t always translate cleanly to Python.\\n\\nIn Python, we get powerful tools out of the box: first-class functions, flexible constructors, easy memoization with `functools.lru_cache`, and dynamic types. When we use those tools effectively, many classic patterns fade into the background, not because we\u2019re ignoring good design, but because we\u2019ve outgrown the constraints that made those patterns necessary in the first place.\\n\\nSo when you\'re tempted to reach for an old-school design pattern, pause and ask: _Is there a simpler, more natural way to express this in Python?_\\n\\nMost of the time, there is.\\n\\n\\n---\\n\\nLinks:\\n\\n[GOF flyweight pattern](https://www.cs.unc.edu/~stotts/GOF/hires/pat4ffso.htm)\\n\\n[string interning from cpython github repo](https://github.com/python/cpython/blob/main/InternalDocs/string_interning.md)\\n\\n\\n[Random flyweight implementation in python I found online](https://github.com/gennad/Design-Patterns-in-Python/blob/master/flyweight.py)\\n\\n\\n\\n--- \\n\\nThank list\\n\\n- Thanks u/commy2 for fixing the flyweight user code example\\n\\n- Thanks u/camel_hopper for fixing typo \\"Graphic\\" -> \\"Graphics\\"\\n\\n- Thanks u/tomysshadow for fixing typo \\"GrpahicTool\\" -> \\"GraphicTool\\""},{"id":"design-patterns-you-should-unlearn-in-python-part1","metadata":{"permalink":"/ja/blog/design-patterns-you-should-unlearn-in-python-part1","source":"@site/blog/2025-06-19T14_07-design-patterns-you-should-unlearn-in-python/content.md","title":"Design Patterns You Should Unlearn in Python-Part1","description":"image-1.jpg","date":"2025-06-19T00:00:00.000Z","tags":[{"inline":false,"label":"python","permalink":"/ja/blog/tags/python","description":"general dicussion about programming in python"},{"inline":true,"label":"design patterns","permalink":"/ja/blog/tags/design-patterns"},{"inline":false,"label":"OOP","permalink":"/ja/blog/tags/oop","description":"Object-oriented programming principles and practices"}],"readingTime":8.09,"hasTruncateMarker":true,"authors":[{"name":"raceychan","title":"author of lihil, a developer.","url":"https://github.com/raceychan","page":{"permalink":"/ja/blog/authors/raceychan"},"imageURL":"https://github.com/raceychan.png","key":"raceychan"}],"frontMatter":{"slug":"design-patterns-you-should-unlearn-in-python-part1","title":"Design Patterns You Should Unlearn in Python-Part1","authors":["raceychan"],"tags":["python","design patterns","oop"],"toc_min_heading_level":2,"toc_max_heading_level":5},"unlisted":false,"prevItem":{"title":"Design Patterns You Should Unlearn in Python-Part2","permalink":"/ja/blog/design-patterns-you-should-unlearn-in-python-part2"},"nextItem":{"title":"Decorators and Functional programming","permalink":"/ja/blog/decorators-and--functional-programming"}},"content":"![image-1.jpg](https://unsplash.com/photos/ipmwlGIXzcw/download?ixid=M3wxMjA3fDB8MXxhbGx8fHx8fHx8fHwxNzUwMzQwMjYwfA&force=true&w=1920)\\n\\nSearch for \u201cdesign patterns in Python\u201d and you\u2019ll be rewarded with a parade of tutorials showing off how to faithfully re-implement Gang of Four patterns \u2014 complete with class diagrams, factory hierarchies, and enough boilerplate to heat a small village. They\u2019ll make you feel like you\u2019re writing \u201cserious\u201d code. Smart. Professional. Enterprise-ready.\\n\\nBut here\u2019s the problem: **most of these patterns solve problems Python doesn\u2019t have**. They were designed for languages like Java and C++, where you have to jump through hoops just to get basic things done \u2014 no first-class functions, no dynamic typing, no modules as namespaces. Of course you\u2019d need a Factory or a Singleton if your language gives you nothing else to work with.\\n\\nBlindly copying those patterns into Python doesn\u2019t make you clever. It makes your code harder to read, harder to test, and harder to explain to the next poor soul who has to maintain it \u2014 possibly you, three months from now.\\n\\nIn this post, we\u2019ll go over a few classic GOF patterns that you should unlearn as a Python developer. For each one, we\u2019ll look at:\\n\\n1. How it\u2019s usually (and badly) implemented in Python,\\n2. Why it actually made sense back when people were writing Java in 2001,\\n3. And what the Pythonic alternative looks like \u2014 because yes, there\u2019s almost always a simpler way.\\n\\nLet\u2019s start with the biggest offender: **Creational Patterns** \u2014 aka, a whole category of solutions to problems Python already solved.\\n\\n\x3c!-- truncate --\x3e\\n\\n### Singleton: When You Want a Global Variable but Make It Look Fancy\\n\\nAh yes, the Singleton. The go-to pattern for developers who want global state but still want to feel like they\u2019re writing _object-oriented_ code. In Python, you\u2019ll often see this \u201csmart\u201d implementation using `__new__` and a class variable:\\n\\n\\n```python\\nclass Singleton:\\n    _instance: \\"Singleton\\" | None = None\\n\\n    def __new__(cls, *args, **kwargs):\\n        if cls._instance is None:\\n            cls._instance = super().__new__(cls)\\n        return cls._instance\\n```\\n\\nIt _feels_ clever \u2014 until you try to actually use it.\\n\\n```python\\ns1 = Singleton(name=\\"Alice\\", age=30)\\ns2 = Singleton(name=\\"Bob\\", age=25)\\n\\nprint(s1.name)  # \'Alice\'\\nprint(s2.name)  # Still \'Alice\'!\\n```\\n\\n\\nWhat happened? Well, it turns out you\u2019re always getting the same instance, no matter what parameters you pass. Your second call to `Singleton(name=\\"Bob\\", age=25)` didn\u2019t create anything new \u2014 it just silently reused the original object, with its original attributes. No warning. No error. Just quietly wrong.\\n\\n\\nBut things get worse when you try to subclass it:\\n\\n```python\\nclass DBConnection:\\n    _instance = None\\n    def __new__(cls, *args, **kwargs):\\n        if cls._instance is None:\\n            cls._instance = super().__new__(cls)\\n        return cls._instance\\n\\nclass MySqlConnection(DBConnection): ...\\nclass PostGresConnection(DBConnection): ...\\n\\nconn1 = MySqlConnection()\\nconn2 = PostGresConnection()\\n```\\n\\nYou might expect two separate objects, one for each subclass. But nope \u2014 both `conn1` and `conn2` are the same instance. That\u2019s because `_instance` lives on the base class, not per subclass. So congratulations: **you\u2019ve now built the ultimate surprise box.** `PostGresConnection()` might return a `MySqlConnection`, and `MySqlConnection()` might give you a `PostGresConnection`. It all depends on which one you happened to instantiate first.\\n\\nHope your app enjoys the roulette.\\n\\n### Why Singleton Made Sense in C++\\n\\nLet\u2019s be clear: the Singleton pattern didn\u2019t appear out of thin air. It was born in the wild west of C++ \u2014 a language with no real module system and only a limited notion of namespaces.\\n\\nIn C++, your code lives in header and source files, all crammed together during compilation. There\u2019s no clean way to say \u201cthis is private to this file\u201d or \u201cthis global object only exists once\u201d without jumping through hoops. The language gives you **global variables**, which quickly become a mess if you don\u2019t control their initialization and lifetime carefully.\\n\\nBecause C++ doesn\u2019t have modules (before c++20) or proper package systems, Singleton was a clever hack to guarantee **exactly one** instance of a class, avoiding the nightmare of duplicate globals and multiple definitions. It\u2019s like the language forced you to invent a pattern to handle what Python solves with a simple module-level object.\\n\\n```cpp\\n// logger.h\\n\\n#ifndef LOGGER_H\\n#define LOGGER_H\\n\\nclass Logger {\\npublic:\\n    void log(const char* msg);\\n};\\n\\nextern Logger globalLogger; // Declaration\\n#endif\\n\\n// logger.cpp\\n\\n#include \\"logger.h\\"\\n#include <iostream>\\n\\nLogger globalLogger; // Definition\\n\\nvoid Logger::log(const char* msg) {\\n    std::cout << msg << std::endl;\\n}\\n\\n// main.cpp\\n\\n#include \\"logger.h\\"\\n\\nint main() {\\n    globalLogger.log(\\"Starting the app\\");\\n    return 0;\\n}\\n\\n```\\nThe `globalLogger` is defined in one translation unit (`logger.cpp`), but if you accidentally define it in multiple places, the linker will complain about duplicate symbols. Managing this global state is tricky \u2014 and the Singleton pattern wraps this idea into a class that controls its own single instance, so you don\u2019t have to worry about multiple definitions.\\n\\nSo yes, Singleton is basically a band-aid for C++\u2019s lack of modularity and clean global state management \u2014 not a holy grail of software design.\\n\\n### The Pythonic Alternative: Just Use Modules (Seriously)\\n\\nIf you want a **global, single instance** in Python, you don\u2019t need to reinvent the wheel with complicated Singleton classes. Python already gives you everything you need \u2014 in the form of **modules**.\\n\\nJust create your object at the module level, and it\u2019s guaranteed to be a singleton for as long as that module is imported:\\n\\n\\n```python\\n# settings.py\\nfrom typing import Final\\n\\nclass Settings: ...\\n\\nsettings: Final[Settings] = Settings() # add typing.Final to settings so type checker would complain if someone is trying to re-assign the settings object.\\n```\\n\\n\\n### Want to Delay Creation? Use Closures\\n\\nOkay, maybe you want to **delay** creating the object until it\u2019s actually needed \u2014 lazy initialization. Still no need for Singleton patterns.\\n\\nUse a simple function with a closure and an internal variable to store the instance:\\n\\n\\n```python\\ndef _settings():\\n    settings: Settings = Settings()\\n\\n    def get_settings() -> Settings:\\n        return settings\\n\\n    def set_settings(value: Settings) -> None:\\n        nonlocal settings\\n        settings = value\\n\\n    return get_settings, set_settings\\n\\nget_settings, set_settings = _settings()\\n```\\n\\n[Example of this pattern from github](https://github.com/raceychan/lihil/blob/master/lihil/config/__init__.py)\\n\\n\\n\\nThis approach is especially useful when your settings object depends on values only available at runtime \u2014 for example, the path to an environment file (`env_file: Path`). With lazy initialization via closure, you can defer creating the `Settings` instance until you have all the necessary information, instead of forcing it at import time.\\n\\n\\n### Builder Pattern: Overcomplicating Object Creation Like a Boss\\n\\nIf you\u2019ve dabbled in design patterns, you\u2019ve probably seen the Builder pattern praised as the elegant way to construct complex objects step-by-step. In languages like Java or C++, where constructors can\u2019t have default arguments and object immutability is king, this makes some sense.\\n\\nBut in Python? Oh boy. You\u2019ll often find \u201cbuilders\u201d that look like this:\\n\\n```python\\nclass CarBuilder:\\n    def __init__(self):\\n        self._color = None\\n        self._engine = None\\n\\n    def set_color(self, color: str) -> \\"CarBuilder\\":\\n        self._color = color\\n        return self\\n\\n    def set_engine(self, engine: str) -> \\"CarBuilder\\":\\n        self._engine = engine\\n        return self\\n\\n    def build(self) -> \\"Car\\":\\n        return Car(color=self._color, engine=self._engine)\\n\\nclass Car:\\n    def __init__(self, color: str, engine: str):\\n        self.color = color\\n        self.engine = engine\\n\\ncar = (\\n    CarBuilder()\\n    .set_color(\\"red\\")\\n    .set_engine(\\"V8\\")\\n    .build()\\n)\\n```\\n\\nThis is the kind of code that makes you look like you know what you\u2019re doing... until you realize you just reinvented named arguments with method chaining and extra classes. All that boilerplate, just to avoid using Python\u2019s default arguments or keyword arguments?\\n\\nCongratulations! You\u2019ve just made a _builder_ to work around a problem Python already solves out of the box.\\n\\n\\nwhy Builder pattern is often needed due to lack of default parameter values:\\n```java\\npublic class Car {\\n    private final String color;\\n    private final String engine;\\n\\n    private Car(Builder builder) {\\n        this.color = builder.color;\\n        this.engine = builder.engine;\\n    }\\n\\n    public static class Builder {\\n        private String color;   // no default value\\n        private String engine;  // no default value\\n\\n        public Builder setColor(String color) {\\n            this.color = color;\\n            return this;\\n        }\\n\\n        public Builder setEngine(String engine) {\\n            this.engine = engine;\\n            return this;\\n        }\\n\\n        public Car build() {\\n            // You might want to add validation here\\n            return new Car(this);\\n        }\\n    }\\n\\n    public static void main(String[] args) {\\n        Car car = new Car.Builder()\\n            .setColor(\\"Red\\")\\n            .setEngine(\\"V8\\")\\n            .build();\\n    }\\n}\\n```\\n\\nIn Java, constructors can\u2019t have default values for parameters, and method overloading quickly becomes cumbersome for many options. The Builder pattern solves this by allowing step-by-step construction with optional parameters.\\n\\n### The Pythonic Alternative: Default Arguments and Factory Functions \u2014 No Builders Required\\n\\nSo how do we build complex objects in Python without all the ceremony? Simple: we just use the language like it was meant to be used.\\n\\n#### 1. Use Default Arguments Like a Normal Human\\n\\nIn Python, we don\u2019t need to chain setters just to create an object. We can give parameters default values right in the constructor \u2014 no extra classes needed:\\n\\n```python\\nclass Car:\\n    def __init__(self, color: str = \\"black\\", engine: str = \\"V4\\"):\\n        self.color = color\\n        self.engine = engine\\n\\ncar = Car(color=\\"red\\", engine=\\"V8\\")\\n```\\n\\nBoom. Readable, concise, and infinitely easier to test. You want a default car? Just call `Car()`. You want something fancy? Pass in the arguments. Done.\\n\\n#### 2. Want Something Fancier? Use a Factory Function with Overloads\\n\\nIf you want more control or better editor support (e.g. different argument combos), a **factory function** with `typing.overload` gives you flexibility _without_ creating a whole `Builder` class:\\n\\n```python\\nfrom typing import overload\\n\\nclass Car:\\n    def __init__(self, color: str, engine: str):\\n        self.color = color\\n        self.engine = engine\\n\\n@overload\\ndef make_car() -> Car: ...\\n@overload\\ndef make_car(color: str) -> Car: ...\\n@overload\\ndef make_car(color: str, engine: str) -> Car: ...\\n\\ndef make_car(color: str = \\"black\\", engine: str = \\"V4\\") -> Car:\\n    return Car(color=color, engine=engine)\\n\\ncar1 = make_car()\\ncar2 = make_car(\\"red\\")\\ncar3 = make_car(\\"blue\\", \\"V8\\")\\n```\\n\\nYou get clean logic, helpful autocompletion in your IDE, and zero boilerplate. Imagine that \u2014 solving the builder problem with just functions and defaults. Who knew?"},{"id":"decorators-and--functional-programming","metadata":{"permalink":"/ja/blog/decorators-and--functional-programming","source":"@site/blog/2025-05-28T10_33-decorators-and--functional-programming/content.md","title":"Decorators and Functional programming","description":"lego","date":"2025-05-28T00:00:00.000Z","tags":[{"inline":false,"label":"python","permalink":"/ja/blog/tags/python","description":"general dicussion about programming in python"}],"readingTime":9.015,"hasTruncateMarker":true,"authors":[{"name":"raceychan","title":"author of lihil, a developer.","url":"https://github.com/raceychan","page":{"permalink":"/ja/blog/authors/raceychan"},"imageURL":"https://github.com/raceychan.png","key":"raceychan"}],"frontMatter":{"slug":"decorators-and--functional-programming","title":"Decorators and Functional programming","authors":["raceychan"],"tags":["python"],"toc_min_heading_level":2,"toc_max_heading_level":5},"unlisted":false,"prevItem":{"title":"Design Patterns You Should Unlearn in Python-Part1","permalink":"/ja/blog/design-patterns-you-should-unlearn-in-python-part1"},"nextItem":{"title":"Set Up User Authentication in Minutes \u2014 With or Without a Standalone Database Using lihil-auth","permalink":"/ja/blog/lihil-auth"}},"content":"![lego](./lego.jpg)\\n\\nI often see people ask how to \\"do functional programming in Python\\"\u2014as if it requires special tools or libraries.\\n\\nBut the truth is, many Python developers are already using functional programming techniques without realizing it. One of the clearest examples is the use of decorators.\\n\\nDecorators are not only a staple of modern Python codebases but also a practical bridge between traditional imperative programming and the functional programming paradigm.\\n\\n\x3c!-- truncate --\x3e\\n\\n## The Essence of Decorators\\n\\nAt their core, decorators are higher-order functions: a fundamental concept in functional programming.\\n\\n### What is a Higher-Order Function?\\n\\nAccording to Wikipedia, a higher-order function is a function that either(or both):\\n\\n- Takes one or more functions as arguments\\n- Returns a function as its result.\\n\\nLet me give a naive example for this\\n\\n```python\\nfrom typing import Callable\\n\\ndef dummy(func: Callable[..., Any]) -> Callable[..., Any]:\\n    return func\\n```\\n\\nAt first glance, this dummy function seems trivial.\\n\\nit just returns the function it receives without any modification.\\n\\nHowever, with a slight adjustment, we can transform it into something more useful:\\n\\n```python\\nfrom typing import ParamSpec, TypeVar\\n\\nP, R = ParamSpec(\\"P\\"), TypeVar(\\"R\\")\\n\\ndef dummy(func: Callable[P, R]) -> Callable[P, R]:\\n    def wrapper(*args: P.args, **kwargs: P.kwargs) -> R:\\n        result = func(*args, **kwargs)\\n        return result\\n    return wrapper\\n```\\n\\nThis is a decorator! In Python, decorators satisfy both criteria:\\n they take a function as input and often return a new function(in our example, `wrapper`) with modified behavior.\\n\\nSo, decorators in Python are not just a convenient syntax\u2014they\u2019re a direct, real-world application of higher-order function concepts.\\n\\n### Functions as First-Class Citizens\\n\\nHow can Python support decorators so seamlessly? The answer lies in a foundational language feature: functions are first-class citizens.\\n\\nThis means functions in Python can be:\\n\\n- Assigned to variables\\n  we can do inside `wrapper`\\n\\n  ```python\\n  new_func = func\\n  result = func(*args, **kwargs)\\n  ```\\n\\n- Passed as arguments\\n  This\\n\\n  ```python\\n  @dummy\\n  def add(a: int, b: int) -> int:\\n      return a + b\\n  ```\\n\\n  is equivalent to\\n\\n  ```python\\n  add = dummy(add)\\n  ```\\n\\n  when we decorate `add` with `dummy`, python would automatically passes `add` as an argument to `dummy`\\n\\n- Returned from other functions\\n  Inside `dummy`, we return `wrapper` as a value, which is a function defined within `dummy`.\\n\\n- Stored in data structures like lists or dictionaries\\n  we won\'t dig deep into this, but when dummy is defined, it is stored within module\'s global namespace, which is a dict under the hood.\\n\\nIn contrast, in some statically typed or older programming languages(say java before java 8), functions are not first-class.\\n\\nThis would break in pre-java8\\n\\n```java\\npublic class Example {\\n    public static void callTwice(Function func) {\\n        func(); // Error: not a valid function call\\n        func();\\n    }\\n\\n    public static void main(String[] args) {\\n        callTwice(sayHello); // sayHello isn\'t a value\\n    }\\n\\n    public static void sayHello() {\\n        System.out.println(\\"Hello\\");\\n    }\\n}\\n```\\n\\n## Therefore...\\n\\nIf you\'ve used a decorator like `@functools.lru_cache`, `@app.get`, or `@login_required`, then you\'ve already dipped your toes into functional programming. You\u2019re working with functions that modify or enhance the behavior of other functions\u2014precisely the kind of thing functional programming is all about.\\n\\n## Functional Programming with Decorators\\n\\nDecorators don\'t just align with functional programming.\\n\\nthey can enable several important techniques:\\n\\n### 1. Function Composition\\n   In functional programming, composition is the idea of building complex behavior by combining simple functions. Decorators can be used to layer transformations or validations around a core function, much like composing small functions into a pipeline.\\n\\n   You can chain multiple decorators to achieve a composition-like behavior, each adding behavior before or after the main function is run.\\n\\n   ```python\\n   @decor1\\n   @decor2\\n   @decor3\\n   def decor(a: int, b: int) -> int: ...\\n   ```\\n\\n   This pattern is powerful, but it comes with some caveats:\\n\\n   - Signature incompatibility: \\n   If one decorator modifies the function\u2019s signature (e.g., changes the number or type of arguments), it may break compatibility with other decorators in the chain.For decorators that need to inspect the function signature, if one decorator does not preserve it, the others may break.\\n\\n   - Order sensitivity: The order in which decorators are applied matters. For example, using `@abc.abstractmethod` on a method that has already been wrapped by another decorator may lead to incorrect behavior or errors.\\n\\n   - Readability: As the number of decorators grows, it becomes harder to understand what the function actually does at a glance.\\n\\n   #### Example from lihil\\n\\n   In lihil, an endpoint can receive multiple plugins (which are essentially decorators) using a cleaner and more structured syntax:\\n\\n   ```python\\n   @user.post(plugins=[plugin1, plugin2, plugin3])\\n   async def create_user(): ...\\n   ```\\n\\n   Under the hood, lihil applies these plugins in sequence by decorating the endpoint function:\\n\\n   ```python\\n   for plugin in plugins:\\n       func = plugin(func)\\n   ```\\n\\n   This approach maintains the core idea of composition while improving clarity and control over the decoration process.\\n\\n### 2. Currying\\n\\n   Currying is the process of transforming a function that takes multiple arguments into a sequence of functions that each take a single argument. While Python doesn\'t support automatic currying like Haskell, you can manually simulate currying using decorators\u2014returning nested functions that capture arguments through closure.\\n\\n   This is especially powerful when writing configuration-like decorators, where parameters are fixed upfront and later used to modify a function\'s behavior.\\n\\n   Consider the following example:\\n\\n   ```python\\n    def curry(func: Callable[..., R], *curry_args: Any, **curry_kwargs: Any):\\n        def wrapper(*args: Any, **kwargs: Any) -> R:\\n            return func(*(curry_args + args), **(curry_kwargs | kwargs))\\n        return wrapper\\n   ```\\n\\n   Here, curry is a higher-order function that returns a new function (wrapper) with some arguments pre-filled. These pre-filled values are remembered through closure, and the remaining arguments can be supplied later when the returned function is called.\\n\\n   To demonstrate how this works, imagine a simple subtraction function:\\n\\n   ```python\\n   def sub(a: int, b: int) -> int:\\n       return a - b\\n\\n   sub_five = curry(sub, b=5)\\n   assert sub_five(a=8) == 3\\n   ```\\n\\n   We can use curry to fix one of the arguments, say b = 5, creating a new function that subtracts 5 from any input\\n\\n   By pre-binding the second argument `b`, we\'ve effectively turned `sub(a, b)` into a function that only needs `a`. This mirrors the essence of currying in functional programming\u2014progressively transforming a multi-argument function into a chain of single-argument calls.\\n\\n### 3. Closures\\n   A closure occurs when a function \\"remembers\\" variables from the scope in which it was created, even after that scope has finished executing. This is how decorators store context\u2014whether it\'s a permission requirement, a configuration flag, or a runtime condition.\\n\\n   Closures are what make decorators stateful, enabling powerful behaviors like caching, logging, or retry logic without modifying the function\u2019s internal logic. They allow decorators to wrap and extend functions while retaining information across calls.\\n\\n   let\'s take a look at a real-world example: Python\u2019s built-in lru_cache decorator from the functools module.\\n\\n   Internally, it uses a closure to remember the function\u2019s arguments and their corresponding results.\\n\\n   Here\'s a simplified version of its implementation (based on Python 3.12), with some details omitted to highlight the key point:\\n\\n   ```python\\n    def _lru_cache_wrapper(user_function, maxsize, typed, _CacheInfo):\\n        # Constants shared by all lru cache instances:\\n        sentinel = object()          # unique object used to signal cache misses\\n        make_key = _make_key         # build a key from the function arguments\\n\\n        cache = {}\\n        hits = misses = 0\\n\\n         # case when maxsize is None\\n         def wrapper(*args, **kwds):\\n             # Simple caching without ordering or size limit\\n             nonlocal hits, misses\\n             key = make_key(args, kwds, typed)\\n             result = cache_get(key, sentinel)\\n             if result is not sentinel:\\n                 hits += 1\\n                 return result\\n             misses += 1\\n             result = user_function(*args, **kwds)\\n             cache[key] = result\\n             return result\\n   ```\\n\\n   Here, the inner function `wrapper` forms a closure over several variables\u2014`cache`, `hits`, `misses`, and `make_key`(a util function).\\n\\n   These variables live outside the wrapper function, but remain accessible to it even after `_lru_cache_wrapper` has finished executing. As a result, wrapper is able to remember past function calls and cache results accordingly.\\n\\n   This technique enables powerful optimizations like memoization, all while keeping the decorator\u2019s logic entirely separate from the original function body.\\n\\n### Other Functional Programming Techniques in Python\\n\\nBeyond decorators, Python supports many functional idioms that align with the same principles:\\n\\n1. Comprehensions\\n   list, dict, and set comprehensions are Python\u2019s upgrades to `map` and `filter`, expressed in a concise and readable way. They\'re pure, declarative, and avoid side effects.\\n\\n2. Generators\\n   Generators support lazy evaluation, a key technique in functional programming. Using yield, Python functions can produce a sequence of results over time, supporting pipelines and memory-efficient data flows.\\n\\n3. Built-in Functions\\n   Python\'s standard library includes functional tools like map, filter, reduce, any, all, and functools.partial. These utilities operate on data immutably and often use higher-order functions\u2014core values of the functional paradigm.\\n\\n### Put them all together\\n\\nLet\'s write some functions that illustrate these concepts.\\n\\n```python\\nT = TypeVar(\\"T\\")\\n\\ndef is_even(x: int) -> bool:\\n    return (x % 2) == 0\\n\\ndef larger_than(x: int, threshold: int) -> bool:\\n    return x > threshold\\n```\\n\\nNow we define a utility function that checks whether a value satisfies a list of conditions. This uses a generator expression and `all()` for declarative, short-circuiting evaluation:\\n\\n```python\\ndef meets_conditions(*conditions: Callable[[T], bool], target: T) -> bool:\\n    return all(condition(target) for condition in conditions) # generator comprehension\\n```\\n\\nFinally, we wrap everything into a decorator. It accepts multiple conditions and applies them to the result of a function. We also use `functools.partial` to pre-fill parameters\u2014a form of currying:\\n\\n```python\\ndef check_result(*conditions: Callable[[T], bool]):\\n    def decorator(func: Callable[P, T]):\\n        def wrapper(*args: P.args, **kwargs: P.kwargs) -> T:\\n            result = func(*args, **kwargs)\\n            if not meets_conditions(*conditions, target=result):\\n                raise ValueError(\\"Return value did not meet required conditions\\")\\n            return result\\n\\n        return wrapper\\n\\n    return decorator\\n\\n@check_result(is_even, partial(larger_than, threshold=5))\\ndef add(a: int, b: int) -> int:\\n    return a + b\\n\\n\\nassert add(3, 5) == 8\\nadd(1, 1) # This would fail\\nadd(4, 3) # This would fail too\\n```\\n\\n\\n## Wrapping Up\\n\\nDecorators in Python are a clear, powerful example of how functional programming concepts can thrive in an imperative language. By understanding decorators as higher-order functions, we unlock a whole world of expressive, reusable, and modular code.\\n\\nAnd while the classic decorator pattern is \u201ca function that takes a function and returns a function,\u201d it doesn\u2019t stop there.\\n\\nIn Python, methods can receive and return other methods, and callable objects (like classes with __call__) can decorate other callables. \\n\\nThese variations still follow the same core idea:\\n\\n> taking one callable and returning another, often with enhanced behavior.\\n\\nThis flexibility is what makes decorators such a practical bridge to functional programming. Whether you\u2019re enforcing constraints, composing behaviors, caching results, or injecting dependencies, decorators offer a clean, composable, and Pythonic way to do it\u2014all while leveraging first-class functions and closures.\\n\\nWhat do you think? Have you used decorators beyond the classic function-to-function pattern?\\n\\nWould you be interested in exploring the object-oriented side of decorators\u2014like how methods or callable classes can act as decorators too?\\n\\nLet me know your thoughts or questions\u2014I\'d love to hear how you use (or plan to use) decorators in your own projects!"},{"id":"lihil-auth","metadata":{"permalink":"/ja/blog/lihil-auth","source":"@site/blog/2025-05-26-lihil-auth/content.md","title":"Set Up User Authentication in Minutes \u2014 With or Without a Standalone Database Using lihil-auth","description":"security","date":"2025-05-26T00:00:00.000Z","tags":[{"inline":false,"label":"web development","permalink":"/ja/blog/tags/web-development","description":"Best practices of webdevlopment"},{"inline":false,"label":"authentication","permalink":"/ja/blog/tags/authentication","description":"Authentication and authorization in web applications"}],"readingTime":4.075,"hasTruncateMarker":true,"authors":[{"name":"raceychan","title":"author of lihil, a developer.","url":"https://github.com/raceychan","page":{"permalink":"/ja/blog/authors/raceychan"},"imageURL":"https://github.com/raceychan.png","key":"raceychan"}],"frontMatter":{"slug":"lihil-auth","title":"Set Up User Authentication in Minutes \u2014 With or Without a Standalone Database Using lihil-auth","authors":["raceychan"],"tags":["web-development","authentication"],"toc_min_heading_level":2,"toc_max_heading_level":5},"unlisted":false,"prevItem":{"title":"Decorators and Functional programming","permalink":"/ja/blog/decorators-and--functional-programming"},"nextItem":{"title":"What to Do When HTTP Status Codes Don\u2019t Fit Your Business Error","permalink":"/ja/blog/what-to-do-when-http-status-codes-dont-fit-your-business-error"}},"content":"![security](./security.jpg)\\n\\nAs someone who has worked on multiple web projects, I\u2019ve found user authentication to be a recurring pain point. Whether I was integrating a third-party auth provider like Supabase, or worse \u2014 rolling my own auth system \u2014 I often found myself rewriting the same boilerplate:\\n\\n- Configuring JWTs\\n\\n- Decoding tokens from headers\\n- Serializing them back\\n- Hashing passwords\\n- Validating login credentials\\n\\nAnd that\u2019s not even touching error handling, route wiring, or OpenAPI documentation.\\n\\nSo I built lihil-auth, a plugin system that makes user authentication a breeze. It supports both third-party platforms like `Supabase` and self-hosted solutions using JWT \u2014 with minimal effort.\\n\\n\x3c!-- truncate --\x3e\\n\\n### Supabase Auth in One Line\\n\\nIf you\'re using Supabase, setting up authentication is as simple as:\\n\\n```python\\nfrom lihil import Lihil\\nfrom lihil.plugins.auth.supabase import signin_route_factory, signup_route_factory\\n\\napp = Lihil()\\napp.include_routes(\\n    signin_route_factory(route_path=\\"/login\\"),\\n    signup_route_factory(route_path=\\"/signup\\"),\\n)\\n```\\n\\nHere, `signin_route_factory` and `signup_route_factory` generate the `/login` and `/signup` routes for you, respectively. They handle everything from user registration to login, including password hashing and JWT generation(thanks to supabase).\\n\\nYou can customize credential type by configuring `sign_up_with` parameter, where you might want to use `phone` instead of `email` for signing up users.\\n\\nThese routes immediately become available in your OpenAPI docs (/docs), allowing you to explore, debug, and test them interactively(thanks to swagger-ui):\\n\\n![Supabase Routes](./openapi_supabase_routes.png)\\n![Supabase debug](./openapi_supabase_debug.png)\\n\\nWith just that, you have a ready-to-use login route backed by Supabase.\\n\\n#### Full docs: [Supabase Plugin Documentation](https://lihil.cc/docs/advance/plugin/supabase)\\n\\n### Want to use Your Own Database?\\n\\nNo problem. The JWT plugin lets you manage users and passwords your own way, while lihil takes care of encoding/decoding JWTs and injecting them as typed objects.\\n\\n#### Basic JWT Authentication Example\\n\\nYou might want to include public user profile information in your JWT, such as user ID and role.\\nso that you don\'t have to query the database for every request.\\n\\n```python\\nfrom lihil import Payload, Route\\nfrom lihil.plugins.auth.jwt import JWTAuthParam, JWTAuthPlugin, JWTConfig\\nfrom lihil.plugins.auth.oauth import OAuth2PasswordFlow, OAuthLoginForm\\n\\nme = Route(\\"/me\\")\\ntoken = Route(\\"/token\\")\\n\\njwt_auth_plugin = JWTAuthPlugin(jwt_secret=\\"mysecret\\", jwt_algorithms=\\"HS256\\")\\n\\nclass UserProfile(Struct):\\n    user_id: str = field(name=\\"sub\\")\\n    role: Literal[\\"admin\\", \\"user\\"] = \\"user\\"\\n\\n@me.get(auth_scheme=OAuth2PasswordFlow(token_url=\\"token\\"), plugins=[jwt_auth_plugin.decode_plugin()])\\nasync def get_user(profile: Annotated[UserProfile, JWTAuthParam]) -> User:\\n    assert profile.role == \\"user\\"\\n    return User(name=\\"user\\", email=\\"user@email.com\\")\\n\\n@token.post(plugins=[jwt_auth_plugin.encode_plugin(expires_in_s=3600)])\\nasync def login_get_token(credentials: OAuthLoginForm) -> UserProfile:\\n    return UserProfile(user_id=\\"user123\\")\\n```\\n\\nHere we define a `UserProfile` struct that includes the user ID and role, we then might use the `role` to determine access permissions in our application.\\n\\nYou might wonder if we can trust the `role` field in the JWT. The answer is yes, because the JWT is signed with a secret key, meaning that any information\\nencoded in the JWT is `read-only` and cannot be tampered with by the client. If the client tries to modify the JWT, the signature will no longer match, and the server will reject the token.\\n\\nThis also means that you should not include any sensitive information in the JWT, as it can be decoded by anyone who has access to the token.\\n\\nWe then use `jwt_auth_plugin.decode_plugin` to decode the JWT and inject the `UserProfile` into the request handler.\\nWhen you return `UserProfile` from `login_get_token`, it will automatically be serialized as a JSON Web Token.\\n\\nBy default, the JWT would be returned as oauth2 token response, but you can also return it as a simple string if you prefer.\\nYou can change this behavior by setting `scheme_type` in `encode_plugin`\\n\\n```python\\nclass OAuth2Token(Base):\\n    access_token: str\\n    expires_in: int\\n    token_type: Literal[\\"Bearer\\"] = \\"Bearer\\"\\n    refresh_token: Unset[str] = UNSET\\n    scope: Unset[str] = UNSET\\n```\\n\\nThe client can receive the JWT and update its header for subsequent requests:\\n\\n```python\\ntoken_data = await res.json()\\ntoken_type, token = token_data[\\"token_type\\"], token_data[\\"access_token\\"]\\n\\nheaders = {\\"Authorization\\": f\\"{token_type.capitalize()} {token}\\"} # use this header for subsequent requests\\n```\\n\\n#### Role-Based Authorization Example\\n\\nYou can utilize function dependencies to enforce role-based access control in your application.\\n\\n```python\\ndef is_admin(profile: Annotated[UserProfile, JWTAuthParam]) -> bool:\\n    if profile.role != \\"admin\\":\\n        raise HTTPException(problem_status=403, detail=\\"Forbidden: Admin access required\\")\\n\\n@me.get(auth_scheme=OAuth2PasswordFlow(token_url=\\"token\\"), plugins=[jwt_auth_plugin.decode_plugin()])\\nasync def get_admin_user(profile: Annotated[UserProfile, JWTAuthParam], _: Annotated[bool, use(is_admin)]) -> User:\\n    return User(name=\\"user\\", email=\\"user@email.com\\")\\n```\\n\\nHere, for the `get_admin_user` endpoint, we define a function dependency `is_admin` that checks if the user has an admin role. If the user does not have the required role, the request will fail with a 403 Forbidden Error .\\n\\n#### Returning Simple String Tokens\\n\\nIn some cases, you might always want to query the database for user information, and you don\'t need to return a structured object like `UserProfile`. Instead, you can return a simple string value that will be encoded as a JWT.\\n\\nIf so, you can simply return a string from the `login_get_token` endpoint, and it will be encoded as a JWT automatically:\\n\\n```python\\n@token.post(plugins=[jwt_auth_plugin.encode_plugin(expires_in_s=3600)])\\nasync def login_get_token(credentials: OAuthLoginForm) -> str:\\n    return \\"user123\\"\\n```\\n\\n#### Full docs: [JWT Plugin Documentation](https://lihil.cc/docs/advance/plugin/jwt)\\n\\n## Installation\\n\\n### To use jwt only\\n\\n```bash\\npip install \\"lihil[standard]\\"\\n```\\n\\n### To use both jwt and supabase\\n\\n```bash\\npip install \\"lihil[standard,supabase]\\"\\n```\\n\\n---\\n\\nGithub: [lihil](https://github.com/raceychan/lihil)\\n\\nOfficial Docs: [lihil.cc](https://lihil.cc)"},{"id":"what-to-do-when-http-status-codes-dont-fit-your-business-error","metadata":{"permalink":"/ja/blog/what-to-do-when-http-status-codes-dont-fit-your-business-error","source":"@site/blog/2025-04-27-http_code/content.md","title":"What to Do When HTTP Status Codes Don\u2019t Fit Your Business Error","description":"404mail","date":"2025-04-27T00:00:00.000Z","tags":[{"inline":false,"label":"web development","permalink":"/ja/blog/tags/web-development","description":"Best practices of webdevlopment"}],"readingTime":8.82,"hasTruncateMarker":true,"authors":[{"name":"raceychan","title":"author of lihil, a developer.","url":"https://github.com/raceychan","page":{"permalink":"/ja/blog/authors/raceychan"},"imageURL":"https://github.com/raceychan.png","key":"raceychan"}],"frontMatter":{"slug":"what-to-do-when-http-status-codes-dont-fit-your-business-error","title":"What to Do When HTTP Status Codes Don\u2019t Fit Your Business Error","authors":["raceychan"],"tags":["web-development"],"toc_min_heading_level":2,"toc_max_heading_level":5},"unlisted":false,"prevItem":{"title":"Set Up User Authentication in Minutes \u2014 With or Without a Standalone Database Using lihil-auth","permalink":"/ja/blog/lihil-auth"}},"content":"![404_mail](./404_mail.jpg)\\n\\n### Question:\\n\\n**How would you choose a status code for an order that could not be processed because the customer\'s shipping address is outside the delivery zone?**\\n\\n\x3c!-- truncate --\x3e\\n\\n<details>\\n\\n<summary>Spoiler</summary>\\n\\n### You shouldn\'t be looking for a specific status code for busineess error.\\n\\nInstead, use a 4xx status code with a well-defined structural error response and provide detailed documentation of the error response format.\\n\\n</details>\\n\\nWhether you are struggling to find an appropiate http status code, or if you have a specific http status code to use, this blog is for you.\\n\\n### What is http status code and why you should care\\n\\n#### Status code is popular\\n\\nEven if you are not a technical guy, it is very likley that you have heard these numbers `404`, `502`. This is because http status code is so popular that It is literally everywhere on the internet.\\n\\nHTTP status codes have long been a cornerstone of web application error handling. Defined in RFC 7231, these codes serve as a standardized way for servers to communicate the outcome of a request to the client.\\nThe standard defines several categories of status codes, such as `2xx` for success, `4xx` for client errors, and `5xx` for server errors.\\nQuote from [RFC 7231](https://datatracker.ietf.org/doc/html/rfc7231#section-8.2.2):\\n\\n> HTTP clients are not required to\\n> understand the meaning of all registered status codes, though such\\n> understanding is obviously desirable. However, a client MUST\\n> understand the class of any status code, as indicated by the first\\n> digit, and treat an unrecognized status code as being equivalent to\\n> the x00 status code of that class\\n\\nIt has become an industrial consensus to check these status codes as a way to quickly determine whether a request was successful or failed. For example, many libraries and frameworks will raise an exception if a request results in an error status. Here\'s a simple example using Python\'s `requests` library:\\n\\n```python\\nimport requests\\n\\nresponse = requests.get(\\"https://api.example.com/data\\")\\nresponse.raise_for_status() # this would raise exception when status code > 400\\nprint(\\"Data retrieved successfully!\\")\\n```\\n\\n> In this example, `raise_for_status()` automatically raises an `HTTPError` if the server returns a 4xx or 5xx status code. This is a common pattern in many applications to ensure that only successful requests are processed further.\\n\\n### Why is it difficult to choose a status code for your bussiness error\\n\\nIt\'s common(but not necessarily correct) to use `4xx` codes like `400 Bad Request` or `403 Forbidden` when something goes wrong. For example, a \\"premium\\" user trying to access a feature available only to \\"pro\\" users might return a `403 Forbidden` status. In such cases, the error is clear, and the status code maps well to the scenario.\\n\\nBut as web applications grow in complexity and deal with more nuanced business rules, things get trickier. Consider a scenario where **an order could not be processed because of a mismatch between the customer\'s shipping address and the delivery zone**. How should this issue be represented in terms of HTTP status codes?\\n\\nThere isn\'t an easy or clear answer. While we could use `400 Bad Request`, it doesn\'t quite capture the specific business rule violation that\'s occurring. Similarly, a `409 Conflict` could work in some cases, but it still doesn\u2019t feel precise enough. As the number of potential issues grows\u2014whether they\u2019re related to payment failures, address mismatches, or resource conflicts\u2014the more apparent it becomes that HTTP status codes are not built to handle the full complexity of modern business logic.\\n\\n### Don\'ts\\n\\nCurrently, there are a few ways the industry deals with the problem of handling business logic errors in web applications. These solutions often involve workarounds or generalizations due to the limitations of HTTP status codes. Here are some of the common approaches:\\n\\n1. **Embedding Custom Status Inside Request Body**\\n\\nOne approach is to always return a `200 OK` status code, even when the request fails, and include a custom status code in the response body. This method involves returning a business-specific error code along with additional details.\\n\\n**Example**:\\n\\n```json\\n{\\n  \\"business_code\\": \\"CUSTOMIZED_BUSINESS_ERROR\\",\\n  \\"detail\\": \\"The shipping address is outside the serviceable delivery zone.\\"\\n}\\n```\\n\\nI have personally encountered this solution from my work a several times during my career. when the system contains only a few components, and with detailed documentation, it could work, but as the system grows and additional components (like proxies, API gateways, and logging systems) are added, this keeps creating new problems you wouldn\'t have to solve otherwise.\\n\\n2. self-define 3-digits status code, for example, 6xx means some business rules, 700 means others, etc.\\n\\nSome solutions attempt to define their own set of status codes beyond the standard `2xx`, `4xx`, and `5xx` categories. For example, `6xx` might represent business rules, with specific codes for each scenario (e.g., `700` for some other business logic). While this avoids reading the request body to determine failure, it violates the HTTP standards, meaning many tools might throw errors or not support these codes.\\n**Example**:\\n\\n```python\\n600: CONNECTION ERROR - This indicates a general connection error\\n601: INCOMPLETE ERROR - This indicates sever sends an incomplete page/object (as indicated by Content-Length header)\\n701: ERROR TEXT FOUND - This code is returned if any error text (such as, \\"Service Unavailable\\") are found in the main page (frame HTML contents included). Note that the error text must be defined in advance of the test. Error text means if the text is found, this session should be considered a failure.\\n```\\n\\nAccording to [RFC 7231](https://datatracker.ietf.org/doc/html/rfc7231#section-8.2.2),\\n\\n> New status codes are required to fall under one of the categories\\n> defined in [Section 6](https://datatracker.ietf.org/doc/html/rfc7231#section-6).\\n\\nstatus codes >= 600 are invalid because they fall outside of the defined categories.\\n\\n#### Dos\\n\\n1. **A 4xx status code + Generic Error Message**\\n\\n```json\\n{\\n  \\"status\\": 400,\\n  \\"message\\": \\"Something went wrong\\"\\n}\\n```\\n\\nA common fallback is to return a `4xx` status code (typically `400 Bad Request`) and include a generic error message such as \\"Something went wrong\\" in the response body. This approach hides the real cause of the business logic failure and lumps all client errors into one vague category. While this might suffice for small-scale applications or early prototypes, it quickly becomes inadequate as the complexity of business rules increases.\\n\\nSome systems go a step further by returning a one-line reason phrase or a slightly extended message, but still fall short of conveying structured, actionable error details to clients.\\n\\n2. **Using the Same Status Code for Multiple Business Logic Issues**\\n\\n```json\\n{\\n  \\"status\\": 400,\\n  \\"message\\": \\"Payment failed\\"\\n}\\n\\n{\\n  \\"status\\": 400,\\n  \\"message\\": \\"Invalid shipping address\\"\\n}\\n```\\n\\nAs business logic errors grow in number and variety, some teams attempt to fit them into a limited set of existing status codes. For instance, both a payment failure due to insufficient funds and a mismatch in shipping address might be returned as `400 Bad Request`. While this approach simplifies server-side handling, it severely limits the clarity of error messages, making it hard for clients to distinguish between different types of business failures. This also places unnecessary burden on client-side developers to reverse-engineer the true nature of the error from vague responses.\\n\\n#### Best Practice\\n\\n**Structured Error Message + Documentation (With Standards Compliance)**\\n\\nA thoughtful approach to business rule violations is to return an appropriate `4xx` status code\u2014ideally one that aligns semantically with the error (for example, `407 Proxy Authentication Required`, if applicable)\u2014to indicate that the request was unsuccessful due to a business constraint.\\n\\nIn addition, the response body can include a **structured error message** based on [RFC 9457 (Problem Details for HTTP APIs)](https://datatracker.ietf.org/doc/html/rfc9457), which defines fields such as `type`, `title`, `status`, `detail`, and `instance`. This format encourages clarity and consistency, making it easier for both developers and automated systems to understand, handle, and trace errors.\\n\\nEqually important is having each error type **clearly documented** so that client developers know what an error means and how to address it. Well-maintained documentation enables richer client experiences, reduces guesswork, and helps prevent issues before they arise.\\n\\nStripe does an excellent job in this area with their [dedicated error code documentation](https://docs.stripe.com/error-codes), which provides detailed explanations for a wide range of business-related errors. Their commitment to transparency and developer experience is evident and commendable.\\n\\nThat said, there are a couple of areas where further improvements could enhance the experience even more:\\n\\n- Their structured error format, while clear, doesn\u2019t explicitly follow RFC 9457, and omits fields like `instance` that can be valuable for debugging.\\n- It\u2019s not clear whether their documentation is automatically generated or manually maintained. If it\u2019s the latter, this could introduce challenges in keeping it fully up to date with evolving APIs.\\n\\n### How lihil solves this problem\\n\\n**Structured Error Messages + Auto-Generated Documentation**\\n\\n[`lihil`](https://lihil.cc/) tackles the problem by making structured error handling first-class. You can declare rich, type-safe exceptions by subclassing `HTTPException[T]`, where `T` defines the structure of the error\'s `detail` field. These exceptions can then be directly attached to endpoints using the `errors=` parameter. This not only ensures consistent error responses but also enables `lihil` to automatically generate OpenAPI documentation for each declared error\u2014including a link to a detailed problem page under the \\"External documentation\\" tab.\\n\\n```python title=\\"How you define a structual exception in lihil\\"\\nfrom lihil import Empty, Lihil, Resp, Route, status, Meta\\nfrom lihil.interface import Base\\nfrom lihil.problems import HTTPException\\n\\nclass AddressOutOfScopeProblem(Base):\\n    current_address: Annotated[str, Meta(examples=[\\"home\\"])]\\n    service_radius: Annotated[float, Meta(examples=[3.5])]\\n    distance: Annotated[float, Meta(examples=4)]\\n\\n    message: str = \\"\\"\\n\\n    def __post_init__(self):\\n        self.message = f\\"Your current address {self.current_address} is {self.distance} miles away and our service radius is {self.service_radius}\\"\\n\\nclass InvalidOrderError(HTTPException[AddressOutOfScopeProblem]):\\n    \\"Address out of service zone\\"\\n    __status__ = 422\\n\\n    instance: Annotated[str, Meta(examples=[\\"2cd20e0c-9ddc-4fdc-8f61-b32f62ac784d\\"])]\\n    detail: AddressOutOfScopeProblem\\n\\n\\norders = Route(\\"orders\\")\\n\\n@orders.post(errors=[InvalidOrderError])\\nasync def create_orders() -> Annotated[Empty, status.CREATED]: ...\\n\\nlhl = Lihil(orders)\\n\\nif __name__ == \\"__main__\\":\\n    lhl.run(__file__)\\n```\\n\\nRunning the above code and it is automatically documented in your OpenAPI.\\n\\n![Order error diagram](./order_error.png)\\n\\n### What makes it good.\\n\\nAs you might see from the OpenAPI, each of these error response follows the [RFC 9457](https://datatracker.ietf.org/doc/html/rfc9457) format, including fields like `type`, `title`, `status`, `detail`, and `instance`. You can customize how errors are rendered by registering handlers with `@problem_solver`, which maps specific exceptions or status codes to structured responses. Specific exception handlers take precedence over status-code-based ones, giving you fine-grained control.\\n\\nBy default, `lihil` also generates detailed responses for common issues such as missing parameters, returning structured 422 responses for `InvalidRequestErrors`\u2014complete with field-level information. These responses are not only machine-readable but also fully documented out of the box.\\n\\nBest of all, all this documentation is automatically synced with your code. There\'s no need to manually update or maintain a separate error code reference. `lihil` keeps your API behavior and documentation in perfect alignment."}]}}')}}]);